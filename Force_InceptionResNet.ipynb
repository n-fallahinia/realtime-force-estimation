{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# This model intends to estimate the human finger forces using CNN\n",
    "# based on the coloration features. The FingerNet is based on \n",
    "# MobileNet V2 by google.\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Building the prediction model \n",
    "# on top of the base model \n",
    "# ===============================\n",
    "def buil_model(width, height, depth, classes):\n",
    "    # initialize the input shape and channels dimension to be\n",
    "    # \"channels last\" ordering\n",
    "    IMG_SHAPE = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                                include_top=False,\n",
    "                                                weights='imagenet')\n",
    "    # Show a summary of the model. Check the number of trainable parameters\n",
    "    base_model.trainable = False\n",
    "    # global average layer (also faltten the output of MobileNet)\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    # first FC layer with droupout\n",
    "    linear_layer = tf.keras.layers.Dense(1024, activation='relu')\n",
    "    dropout_layer = tf.keras.layers.Dropout(0.5)\n",
    "    # prediction layer with 3 outputs\n",
    "    prediction_layer = tf.keras.layers.Dense(classes, activation= 'linear')\n",
    "    # build the model using Keras' Sequential API\n",
    "    model = Sequential([\n",
    "        # MobileNet => avgPOOL => FC => RELU => DROPOUT => FC => LINEAR\n",
    "        base_model,\n",
    "        global_average_layer,\n",
    "        linear_layer,\n",
    "        dropout_layer,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    # return the constructed network architecture\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Solver Parameters \n",
    "# ===============================\n",
    "# initialize the number of epochs to train for, batch size, and initial learning rate\n",
    "EPOCHS = 5\n",
    "BS = 32\n",
    "INIT_LR = 1e-3\n",
    "\n",
    "loss_object = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "opt = tf.keras.optimizers.RMSprop(lr=INIT_LR, momentum=0.9)\n",
    "\n",
    "train_loss = tf.keras.metrics.MeanSquaredError(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.RootMeanSquaredError(name='train_accuracy')\n",
    "# test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "# test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Train function\n",
    "# ===============================\n",
    "@tf.function\n",
    "def train_step(image, force):\n",
    "    # keep track of our gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        # make a prediction using the model and then calculate the loss\n",
    "        force_pred = model(image)\n",
    "        loss = loss_object(force, force_pred)\n",
    "    # calculate the gradients using our tape and then update the model weights\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(force, force_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Train the model\n",
    "# ===============================\n",
    "# build our model and initialize our optimizer\n",
    "print(\"[INFO] creating model...\")\n",
    "model = buil_model(224, 224, 3, 3)\n",
    "# model.summary()\n",
    "\n",
    "# compute the number of batch updates per epoch\n",
    "numUpdates = int(train_image.shape[0] / BS)\n",
    "\n",
    "# loop over the number of epochs\n",
    "for epoch in range(0, EPOCHS):\n",
    "\t# show the current epoch number\n",
    "\tprint(\"[INFO] starting epoch {}/{}...\".format(epoch + 1, EPOCHS), end=\"\")\n",
    "\tsys.stdout.flush()\n",
    "\tepochStart = time.time()\n",
    "    # loop over the data in batch size increments\n",
    "\tfor i in range(0, numUpdates):\n",
    "\t\t# determine starting and ending slice indexes for the current batch\n",
    "\t\tstart = i * BS\n",
    "\t\tend = start + BS\n",
    "        # take a step\n",
    "\t\ttrain_step(train_image[start:end], train_image[start:end])\n",
    "        \n",
    "\t# show timing information for the epoch\n",
    "\tepochEnd = time.time()\n",
    "\telapsed = (epochEnd - epochStart) / 60.0\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
    "\tprint(\"took {:.4} minutes\".format(elapsed))\n",
    "    print (template.format(epoch+1, train_loss.result(), train_accuracy.result()*100,)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = 'dog.jpg'\n",
    "# img = image.load_img(img_path, target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# # x = preprocess_input(x)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit73d841da92524ad6a99e10e510e89f0a",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}